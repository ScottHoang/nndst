22:34:19: Namespace(PF_rate=0.8, batch_size=512, bench=False, data='cifar10', death='magnitude', death_rate=0.5, decay_schedule='constant', density=0.2, epochs=450, epochs_explo=150, fix=False, fp16=False, growth='gradient', iters=1, l1=0.0, l2=0.0005, large_death_rate=0.8, log_interval=100, lr=0.1, max_threads=10, mgpu=False, model='vgg16', model_num=3, momentum=0.9, no_cuda=False, nolrsche=True, optimizer='sgd', redistribution='none', resume=None, save_features=False, seed=17, sparse=True, sparse_init='ERK', start_epoch=1, test_batch_size=128, update_frequency=1000, valid_split=0.1, workers=10, world_size=-1)
22:34:19: 


22:34:19: ================================================================================
22:34:19: 
Iteration start: 1/1

22:34:24: VGG(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): ReLU(inplace=True)
    (2): Dropout(p=0.5, inplace=False)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): ReLU(inplace=True)
    (5): Dropout(p=0.5, inplace=False)
    (6): Linear(in_features=4096, out_features=10, bias=True)
  )
)
22:34:24: ============================================================
22:34:24: vgg16
22:34:24: ============================================================
22:34:24: ============================================================
22:34:24: Prune mode: magnitude
22:34:24: Growth mode: gradient
22:34:24: Redistribution mode: none
22:34:24: ============================================================
22:34:27: Train Epoch: 1 [0/45056 (0%)]	Loss: 2.300196 Accuracy: 59/512 (11.523% 
22:47:49: Namespace(PF_rate=0.8, batch_size=512, bench=False, data='cifar10', death='magnitude', death_rate=0.5, decay_schedule='constant', density=0.2, epochs=450, epochs_explo=150, fix=False, fp16=False, growth='gradient', iters=1, l1=0.0, l2=0.0005, large_death_rate=0.8, log_interval=100, lr=0.1, max_threads=10, mgpu=False, model='vgg16', model_num=3, momentum=0.9, no_cuda=False, nolrsche=True, optimizer='sgd', redistribution='none', resume=None, save_features=False, seed=17, sparse=True, sparse_init='ERK', start_epoch=1, test_batch_size=128, update_frequency=1000, valid_split=0.1, workers=10, world_size=-1)
22:47:49: 


22:47:49: ================================================================================
22:47:49: 
Iteration start: 1/1

22:47:54: VGG(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): ReLU(inplace=True)
    (2): Dropout(p=0.5, inplace=False)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): ReLU(inplace=True)
    (5): Dropout(p=0.5, inplace=False)
    (6): Linear(in_features=4096, out_features=10, bias=True)
  )
)
22:47:54: ============================================================
22:47:54: vgg16
22:47:54: ============================================================
22:47:54: ============================================================
22:47:54: Prune mode: magnitude
22:47:54: Growth mode: gradient
22:47:54: Redistribution mode: none
22:47:54: ============================================================
22:47:57: Train Epoch: 1 [0/45056 (0%)]	Loss: 2.300197 Accuracy: 59/512 (11.523% 
22:48:09: 
Training summary: Average loss: 1.7465, Accuracy: 15380/45000 (34.178%)

22:48:10: 
Evaluation: Average loss: 1.5351, Accuracy: 2295/5000 (45.900%)

22:48:10: Current learning rate: 0.1. Time taken for epoch: 15.66 seconds.

22:48:11: Train Epoch: 2 [0/45056 (0%)]	Loss: 1.303493 Accuracy: 269/512 (52.539% 
22:48:22: 
Training summary: Average loss: 1.1986, Accuracy: 25920/45000 (57.600%)

22:48:23: 
Evaluation: Average loss: 1.5407, Accuracy: 2664/5000 (53.280%)

22:48:23: Current learning rate: 0.1. Time taken for epoch: 12.78 seconds.

22:48:24: Train Epoch: 3 [0/45056 (0%)]	Loss: 1.048449 Accuracy: 321/512 (62.695% 
22:48:35: 
Training summary: Average loss: 0.9576, Accuracy: 30142/45000 (66.982%)

22:48:36: 
Evaluation: Average loss: 0.9509, Accuracy: 3374/5000 (67.480%)

22:48:36: Current learning rate: 0.1. Time taken for epoch: 12.90 seconds.

22:48:37: Train Epoch: 4 [0/45056 (0%)]	Loss: 0.900394 Accuracy: 348/512 (67.969% 
22:48:48: 
Training summary: Average loss: 0.7901, Accuracy: 32922/45000 (73.160%)

22:48:49: 
Evaluation: Average loss: 0.9986, Accuracy: 3356/5000 (67.120%)

22:48:49: Current learning rate: 0.1. Time taken for epoch: 13.21 seconds.

22:48:50: Train Epoch: 5 [0/45056 (0%)]	Loss: 0.719291 Accuracy: 387/512 (75.586% 
22:49:01: 
Training summary: Average loss: 0.6908, Accuracy: 34627/45000 (76.949%)

22:49:02: 
Evaluation: Average loss: 1.2516, Accuracy: 2873/5000 (57.460%)

22:49:02: Current learning rate: 0.1. Time taken for epoch: 12.88 seconds.

22:49:03: Train Epoch: 6 [0/45056 (0%)]	Loss: 0.648796 Accuracy: 394/512 (76.953% 
22:49:14: 
Training summary: Average loss: 0.6090, Accuracy: 35859/45000 (79.687%)

22:49:15: 
Evaluation: Average loss: 0.7003, Accuracy: 3794/5000 (75.880%)

22:49:15: Current learning rate: 0.1. Time taken for epoch: 13.07 seconds.

22:49:16: Train Epoch: 7 [0/45056 (0%)]	Loss: 0.520247 Accuracy: 425/512 (83.008% 
22:49:27: 
Training summary: Average loss: 0.5626, Accuracy: 36622/45000 (81.382%)

22:49:28: 
Evaluation: Average loss: 0.6351, Accuracy: 3930/5000 (78.600%)

22:49:28: Current learning rate: 0.1. Time taken for epoch: 13.08 seconds.

22:49:29: Train Epoch: 8 [0/45056 (0%)]	Loss: 0.546675 Accuracy: 421/512 (82.227% 
22:49:41: 
Training summary: Average loss: 0.5105, Accuracy: 37384/45000 (83.076%)

22:49:42: 
Evaluation: Average loss: 0.6695, Accuracy: 3898/5000 (77.960%)

22:49:42: Current learning rate: 0.1. Time taken for epoch: 13.33 seconds.

22:49:42: Train Epoch: 9 [0/45056 (0%)]	Loss: 0.476765 Accuracy: 426/512 (83.203% 
22:49:54: 
Training summary: Average loss: 0.4687, Accuracy: 37983/45000 (84.407%)

22:49:55: 
Evaluation: Average loss: 0.7099, Accuracy: 3842/5000 (76.840%)

22:49:55: Current learning rate: 0.1. Time taken for epoch: 12.93 seconds.

22:49:55: Train Epoch: 10 [0/45056 (0%)]	Loss: 0.412872 Accuracy: 441/512 (86.133% 
22:50:07: 
Training summary: Average loss: 0.4427, Accuracy: 38421/45000 (85.380%)

22:50:08: 
Evaluation: Average loss: 0.4954, Accuracy: 4144/5000 (82.880%)

22:50:08: Current learning rate: 0.1. Time taken for epoch: 12.94 seconds.

22:50:08: Train Epoch: 11 [0/45056 (0%)]	Loss: 0.400726 Accuracy: 442/512 (86.328% 
22:50:20: 
Training summary: Average loss: 0.4148, Accuracy: 38811/45000 (86.247%)

22:50:21: 
Evaluation: Average loss: 0.6354, Accuracy: 3979/5000 (79.580%)

22:50:21: Current learning rate: 0.1. Time taken for epoch: 13.05 seconds.

22:50:21: Train Epoch: 12 [0/45056 (0%)]	Loss: 0.303056 Accuracy: 457/512 (89.258% 
22:50:33: 
Training summary: Average loss: 0.4299, Accuracy: 38639/45000 (85.864%)

22:50:34: 
Evaluation: Average loss: 0.5870, Accuracy: 4051/5000 (81.020%)

22:50:34: Current learning rate: 0.1. Time taken for epoch: 13.28 seconds.

22:50:34: Train Epoch: 13 [0/45056 (0%)]	Loss: 0.402938 Accuracy: 453/512 (88.477% 
22:50:46: 
Training summary: Average loss: 0.4441, Accuracy: 38602/45000 (85.782%)

22:50:47: 
Evaluation: Average loss: 0.6248, Accuracy: 3994/5000 (79.880%)

22:50:47: Current learning rate: 0.1. Time taken for epoch: 13.03 seconds.

22:50:47: Train Epoch: 14 [0/45056 (0%)]	Loss: 0.404839 Accuracy: 442/512 (86.328% 
22:50:59: 
Training summary: Average loss: 0.4003, Accuracy: 39169/45000 (87.042%)

22:51:00: 
Evaluation: Average loss: 0.5896, Accuracy: 4079/5000 (81.580%)

22:51:00: Current learning rate: 0.1. Time taken for epoch: 13.30 seconds.

22:51:01: Train Epoch: 15 [0/45056 (0%)]	Loss: 0.407873 Accuracy: 444/512 (86.719% 
22:51:12: 
Training summary: Average loss: 0.3849, Accuracy: 39441/45000 (87.647%)

22:51:13: 
Evaluation: Average loss: 0.6055, Accuracy: 4040/5000 (80.800%)

22:51:13: Current learning rate: 0.1. Time taken for epoch: 13.13 seconds.

22:51:14: Train Epoch: 16 [0/45056 (0%)]	Loss: 0.368682 Accuracy: 442/512 (86.328% 
22:51:25: 
Training summary: Average loss: 0.3529, Accuracy: 39813/45000 (88.473%)

22:51:26: 
Evaluation: Average loss: 0.6749, Accuracy: 4006/5000 (80.120%)

22:51:26: Current learning rate: 0.1. Time taken for epoch: 13.04 seconds.

22:51:27: Train Epoch: 17 [0/45056 (0%)]	Loss: 0.346801 Accuracy: 456/512 (89.062% 
22:51:38: 
Training summary: Average loss: 0.3378, Accuracy: 40044/45000 (88.987%)

22:51:40: 
Evaluation: Average loss: 0.5422, Accuracy: 4122/5000 (82.440%)

22:51:40: Current learning rate: 0.1. Time taken for epoch: 13.10 seconds.

22:51:40: Train Epoch: 18 [0/45056 (0%)]	Loss: 0.291863 Accuracy: 457/512 (89.258% 
22:51:52: 
Training summary: Average loss: 0.3267, Accuracy: 40184/45000 (89.298%)

22:51:53: 
Evaluation: Average loss: 0.5775, Accuracy: 4113/5000 (82.260%)

22:51:53: Current learning rate: 0.1. Time taken for epoch: 13.21 seconds.

22:51:53: Train Epoch: 19 [0/45056 (0%)]	Loss: 0.317514 Accuracy: 459/512 (89.648% 
22:52:05: 
Training summary: Average loss: 0.3143, Accuracy: 40408/45000 (89.796%)

22:52:06: 
Evaluation: Average loss: 0.5188, Accuracy: 4188/5000 (83.760%)

22:52:06: Current learning rate: 0.1. Time taken for epoch: 13.39 seconds.

22:52:07: Train Epoch: 20 [0/45056 (0%)]	Loss: 0.296899 Accuracy: 466/512 (91.016% 
22:52:18: 
Training summary: Average loss: 0.3009, Accuracy: 40503/45000 (90.007%)

22:52:19: 
Evaluation: Average loss: 0.6529, Accuracy: 4028/5000 (80.560%)

22:52:19: Current learning rate: 0.1. Time taken for epoch: 13.21 seconds.

22:52:20: Train Epoch: 21 [0/45056 (0%)]	Loss: 0.235919 Accuracy: 470/512 (91.797% 
22:52:32: 
Training summary: Average loss: 0.2984, Accuracy: 40598/45000 (90.218%)

22:52:33: 
Evaluation: Average loss: 0.5070, Accuracy: 4160/5000 (83.200%)

22:52:33: Current learning rate: 0.1. Time taken for epoch: 13.19 seconds.

22:52:33: Train Epoch: 22 [0/45056 (0%)]	Loss: 0.274224 Accuracy: 465/512 (90.820% 
22:52:45: 
Training summary: Average loss: 0.2882, Accuracy: 40802/45000 (90.671%)

22:52:46: 
Evaluation: Average loss: 0.4501, Accuracy: 4283/5000 (85.660%)

22:52:46: Current learning rate: 0.1. Time taken for epoch: 13.14 seconds.

22:52:46: Train Epoch: 23 [0/45056 (0%)]	Loss: 0.253965 Accuracy: 466/512 (91.016% 
22:52:58: 
Training summary: Average loss: 0.2925, Accuracy: 40708/45000 (90.462%)

22:52:59: 
Evaluation: Average loss: 0.6027, Accuracy: 4070/5000 (81.400%)

22:52:59: Current learning rate: 0.1. Time taken for epoch: 13.40 seconds.

22:53:00: Train Epoch: 24 [0/45056 (0%)]	Loss: 0.276961 Accuracy: 457/512 (89.258% 
22:53:11: 
Training summary: Average loss: 0.3241, Accuracy: 40305/45000 (89.567%)

22:53:12: 
Evaluation: Average loss: 0.5144, Accuracy: 4211/5000 (84.220%)

22:53:12: Current learning rate: 0.1. Time taken for epoch: 13.16 seconds.

22:53:13: Train Epoch: 25 [0/45056 (0%)]	Loss: 0.274048 Accuracy: 466/512 (91.016% 
22:53:25: 
Training summary: Average loss: 0.2893, Accuracy: 40756/45000 (90.569%)

22:53:26: 
Evaluation: Average loss: 0.4518, Accuracy: 4260/5000 (85.200%)

22:53:26: Current learning rate: 0.1. Time taken for epoch: 13.43 seconds.

22:53:26: Train Epoch: 26 [0/45056 (0%)]	Loss: 0.246137 Accuracy: 473/512 (92.383% 
22:53:39: 
Training summary: Average loss: 0.2788, Accuracy: 40864/45000 (90.809%)

22:53:40: 
Evaluation: Average loss: 0.4741, Accuracy: 4229/5000 (84.580%)

22:53:40: Current learning rate: 0.1. Time taken for epoch: 14.23 seconds.

22:53:40: Train Epoch: 27 [0/45056 (0%)]	Loss: 0.252914 Accuracy: 470/512 (91.797% 
22:53:53: 
Training summary: Average loss: 0.2713, Accuracy: 41053/45000 (91.229%)

22:53:54: 
Evaluation: Average loss: 0.6889, Accuracy: 3936/5000 (78.720%)

22:53:54: Current learning rate: 0.1. Time taken for epoch: 13.71 seconds.

22:53:54: Train Epoch: 28 [0/45056 (0%)]	Loss: 0.260760 Accuracy: 467/512 (91.211% 
22:54:07: 
Training summary: Average loss: 0.2545, Accuracy: 41289/45000 (91.753%)

22:54:08: 
Evaluation: Average loss: 0.6004, Accuracy: 4071/5000 (81.420%)

22:54:08: Current learning rate: 0.1. Time taken for epoch: 14.07 seconds.

22:54:08: Train Epoch: 29 [0/45056 (0%)]	Loss: 0.194949 Accuracy: 475/512 (92.773% 
22:54:20: 
Training summary: Average loss: 0.2565, Accuracy: 41242/45000 (91.649%)

22:54:21: 
Evaluation: Average loss: 0.7065, Accuracy: 3922/5000 (78.440%)

22:54:21: Current learning rate: 0.1. Time taken for epoch: 13.27 seconds.

22:54:21: Train Epoch: 30 [0/45056 (0%)]	Loss: 0.258785 Accuracy: 470/512 (91.797% 
22:54:33: 
Training summary: Average loss: 0.2524, Accuracy: 41290/45000 (91.756%)

22:54:34: 
Evaluation: Average loss: 0.6750, Accuracy: 4009/5000 (80.180%)

22:54:34: Current learning rate: 0.1. Time taken for epoch: 13.32 seconds.

22:54:35: Train Epoch: 31 [0/45056 (0%)]	Loss: 0.245572 Accuracy: 468/512 (91.406% 
22:54:47: 
Training summary: Average loss: 0.2593, Accuracy: 41150/45000 (91.444%)

22:54:48: 
Evaluation: Average loss: 0.4912, Accuracy: 4216/5000 (84.320%)

22:54:48: Current learning rate: 0.1. Time taken for epoch: 13.40 seconds.

22:54:48: Train Epoch: 32 [0/45056 (0%)]	Loss: 0.229823 Accuracy: 473/512 (92.383% 
22:55:00: 
Training summary: Average loss: 0.2381, Accuracy: 41476/45000 (92.169%)

22:55:01: 
Evaluation: Average loss: 0.6667, Accuracy: 3985/5000 (79.700%)

22:55:01: Current learning rate: 0.1. Time taken for epoch: 13.51 seconds.

22:55:02: Train Epoch: 33 [0/45056 (0%)]	Loss: 0.279096 Accuracy: 468/512 (91.406% 
22:55:14: 
Training summary: Average loss: 0.2363, Accuracy: 41460/45000 (92.133%)

22:55:15: 
Evaluation: Average loss: 0.5710, Accuracy: 4118/5000 (82.360%)

22:55:15: Current learning rate: 0.1. Time taken for epoch: 13.63 seconds.

22:55:15: Train Epoch: 34 [0/45056 (0%)]	Loss: 0.278806 Accuracy: 468/512 (91.406% 
22:55:27: 
Training summary: Average loss: 0.2313, Accuracy: 41591/45000 (92.424%)

22:55:30: Namespace(PF_rate=0.8, batch_size=512, bench=False, data='cifar10', death='magnitude', death_rate=0.5, decay_schedule='constant', density=0.2, epochs=450, epochs_explo=150, fix=False, fp16=False, growth='gradient', iters=1, l1=0.0, l2=0.0005, large_death_rate=0.8, log_interval=100, lr=0.1, max_threads=10, mgpu=False, model='vgg16', model_num=3, momentum=0.9, no_cuda=False, nolrsche=True, optimizer='sgd', redistribution='none', resume=None, save_features=False, seed=17, sparse=True, sparse_init='ERK', start_epoch=1, test_batch_size=128, update_frequency=1000, valid_split=0.1, workers=10, world_size=-1)
22:55:30: 


22:55:30: ================================================================================
22:55:30: 
Iteration start: 1/1

22:55:34: VGG(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): ReLU(inplace=True)
    (2): Dropout(p=0.5, inplace=False)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): ReLU(inplace=True)
    (5): Dropout(p=0.5, inplace=False)
    (6): Linear(in_features=4096, out_features=10, bias=True)
  )
)
22:55:34: ============================================================
22:55:34: vgg16
22:55:34: ============================================================
22:55:34: ============================================================
22:55:34: Prune mode: magnitude
22:55:34: Growth mode: gradient
22:55:34: Redistribution mode: none
22:55:34: ============================================================
