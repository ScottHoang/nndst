{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ff5bb936",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import os.path as osp\n",
    "import torchvision\n",
    "from scheme.EB import EarlyBird\n",
    "from typing import *\n",
    "import tqdm\n",
    "import collections\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "85d0c308",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "DIRS = ['../Early-Bird-Tickets/EB/', '../FreeTickets/results/']\n",
    "DATASETS = ['cifar10']#, 'cifar100']\n",
    "MODELS = ['vgg16']\n",
    "SPARSITY = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f3cadafd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "structured_dirs = osp.join(DIRS[0], DATASETS[0], MODELS[0])\n",
    "unstructured_dirs = osp.join(DIRS[1], DATASETS[0], MODELS[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2c73c958",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "struct_files = [file for file in os.listdir(structured_dirs) if 'ckpt' in file]\n",
    "unstruct_files = [file for file in os.listdir(unstructured_dirs) if 'ckpt' in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "96e8621f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "struct_files.sort(key=lambda x: int(x.split('.')[0][4::]))\n",
    "unstruct_files.sort(key=lambda x: int(x.split('_')[0][4::]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cf96b74e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "paired_files = zip(struct_files, unstruct_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5d0bf6c2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = eval(f\"torchvision.models.{MODELS[0]}\")(num_classes=10).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0279e5ca",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from typing import *\n",
    "from scheme.EB import EarlyBird\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "def generate_macro_mask(model_fn:Callable, s_f:str, us_f:str, n_class:int, sparsity:float=0.8, x_perc:float=0.5) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    desc:\n",
    "        generate a macro or structured mask (channel masking) \n",
    "        from struture and unstructure pruning.\n",
    "    param:\n",
    "        model_fn: model function\n",
    "        s_f: structure file path\n",
    "        us_f: unstructure file path\n",
    "        n_class: number of class\n",
    "        sparsity: degree of sparsity from 0.0 to 1.0\n",
    "        x_perc: cross over percentage. If kernel is x_perc \n",
    "            pruned, it is considered off and vice versa.    return \n",
    "        mask: masking vector \n",
    "    \"\"\"\n",
    "    s_m = model_fn(num_classes=n_class).cuda()\n",
    "    # print(s_f)\n",
    "    # print(us_m)\n",
    "    # print(torch.load(s_f, map_location='cpu')['state_dict'].keys())\n",
    "    s_m.load_state_dict(torch.load(s_f, map_location='cpu')['state_dict'])\n",
    "    us_m = model_fn(num_classes=n_class).cuda()\n",
    "    us_m.load_state_dict(torch.load(us_f, map_location='cpu')['state_dict'])\n",
    "    \n",
    "    s_mask = EarlyBird(sparsity).pruning(s_m, sparsity) \n",
    "    us_mask = micro_to_macro(us_m)\n",
    "    \n",
    "    intersection = s_mask * (s_mask == us_mask).float()    \n",
    "    return s_mask, us_mask, intersection\n",
    "\n",
    "def micro_to_macro(model:torch.nn.Module, x_perc:float=0.55) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    desc:\n",
    "        convert unstructured pruning to structure pruning\n",
    "    param:\n",
    "        model: nn.Module \n",
    "        x_perc: cross over percentage. If kernel is x_perc \n",
    "        pruned, it is considered off and vice versa.\n",
    "    return:\n",
    "        mask: masking vector\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    sparse = 0\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.BatchNorm2d):\n",
    "            total += m.weight.data.shape[0]\n",
    "            \n",
    "    mask = torch.zeros(total)\n",
    "    offset = 0\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            # m.weight (out, in, kH, kW)\n",
    "            # binarize and sum total zero. \n",
    "            # new m.weight (out, in, value), and if value/(kH+kW) > x_perc, \n",
    "            # filter is on. if sum of all filters is > x_perf, channel is on. \n",
    "            # increase offset\n",
    "            out_c, in_c, kH, kW = m.weight.shape\n",
    "            boolean_weight = (m.weight != 0.0).view(out_c, in_c, -1).float().mean(dim=-1).gt(x_perc).float().sum(dim=-1).div(in_c).gt(x_perc).float()\n",
    "            mask[offset:offset+out_c] = boolean_weight\n",
    "            offset += out_c\n",
    "        \n",
    "    return mask \n",
    "\n",
    "def valid_masked_model(model:nn.Module, mask:torch.Tensor) -> bool:\n",
    "    \"\"\"\n",
    "    desc:\n",
    "        determine if the masking vector consitutes a valid model.\n",
    "        A valid model is one such that at least one input channel \n",
    "        makes it to the final output channel.\n",
    "    params:\n",
    "        model: resnet/vgg model construct\n",
    "        mask: a masking vector\n",
    "    return:\n",
    "        bool: Determine whether the pruned model from mask is a \n",
    "        valid model\n",
    "    \"\"\"\n",
    "    offset = 0\n",
    "    total = 0\n",
    "    \n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.BatchNorm2d):\n",
    "            total += m.weight.data.shape[0]\n",
    "    assert mask.size(0) == total\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.BatchNorm2d):\n",
    "            out_c = m.weight.shape[0]\n",
    "            if mask[offset:offset+out_c].sum() > 0:\n",
    "                offset+=out_c\n",
    "            else:\n",
    "                print(offset, out_c)\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "def apply_marco_mask(model:nn.Module, mask:torch.Tensor) -> nn.Module:\n",
    "    \"\"\"\n",
    "    desc: \n",
    "        applying model's mask on batchnorm layer.\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    offset = 0\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.BatchNorm2d):\n",
    "            total += m.weight.data.shape[0]\n",
    "    assert mask.shape[0] == total\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.BatchNorm2d):\n",
    "            out_c = m.weight.data.size(0)\n",
    "            m.weight.data.mul_(mask[offset:offset+out_c])\n",
    "            m.bias.data.mul_(mask[offset:offset+out_c])\n",
    "            offset += out_c\n",
    "    return model\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3ee140fb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for VGG:\n\tMissing key(s) in state_dict: \"features.2.weight\", \"features.2.bias\", \"features.5.weight\", \"features.5.bias\", \"features.12.weight\", \"features.12.bias\", \"features.19.weight\", \"features.19.bias\", \"features.26.weight\", \"features.26.bias\". \n\tUnexpected key(s) in state_dict: \"features.31.weight\", \"features.31.bias\", \"features.31.running_mean\", \"features.31.running_var\", \"features.31.num_batches_tracked\", \"features.34.weight\", \"features.34.bias\", \"features.35.weight\", \"features.35.bias\", \"features.35.running_mean\", \"features.35.running_var\", \"features.35.num_batches_tracked\", \"features.37.weight\", \"features.37.bias\", \"features.38.weight\", \"features.38.bias\", \"features.38.running_mean\", \"features.38.running_var\", \"features.38.num_batches_tracked\", \"features.40.weight\", \"features.40.bias\", \"features.41.weight\", \"features.41.bias\", \"features.41.running_mean\", \"features.41.running_var\", \"features.41.num_batches_tracked\", \"features.1.weight\", \"features.1.bias\", \"features.1.running_mean\", \"features.1.running_var\", \"features.1.num_batches_tracked\", \"features.3.weight\", \"features.3.bias\", \"features.4.weight\", \"features.4.bias\", \"features.4.running_mean\", \"features.4.running_var\", \"features.4.num_batches_tracked\", \"features.8.weight\", \"features.8.bias\", \"features.8.running_mean\", \"features.8.running_var\", \"features.8.num_batches_tracked\", \"features.11.weight\", \"features.11.bias\", \"features.11.running_mean\", \"features.11.running_var\", \"features.11.num_batches_tracked\", \"features.15.weight\", \"features.15.bias\", \"features.15.running_mean\", \"features.15.running_var\", \"features.15.num_batches_tracked\", \"features.18.weight\", \"features.18.bias\", \"features.18.running_mean\", \"features.18.running_var\", \"features.18.num_batches_tracked\", \"features.20.weight\", \"features.20.bias\", \"features.21.running_mean\", \"features.21.running_var\", \"features.21.num_batches_tracked\", \"features.25.weight\", \"features.25.bias\", \"features.25.running_mean\", \"features.25.running_var\", \"features.25.num_batches_tracked\", \"features.27.weight\", \"features.27.bias\", \"features.28.running_mean\", \"features.28.running_var\", \"features.28.num_batches_tracked\", \"features.30.weight\", \"features.30.bias\". \n\tsize mismatch for features.7.weight: copying a param with shape torch.Size([128, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n\tsize mismatch for features.10.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 128, 3, 3]).\n\tsize mismatch for features.10.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for features.14.weight: copying a param with shape torch.Size([256, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for features.17.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 256, 3, 3]).\n\tsize mismatch for features.17.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for features.21.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n\tsize mismatch for features.21.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for features.24.weight: copying a param with shape torch.Size([512, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n\tsize mismatch for features.28.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_1527109/4189837389.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      9\u001B[0m     \u001B[0ms_f\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mosp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstructured_dirs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstruct\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m     \u001B[0mus_f\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mosp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0munstructured_dirs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0munstruct\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 11\u001B[0;31m     \u001B[0ms_mask\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mus_mask\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmacro_mask\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgenerate_macro_mask\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel_fn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0ms_f\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mus_f\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m10\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0.8\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0.55\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     12\u001B[0m     \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnum_classes\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m10\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m     \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload_state_dict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrandom_init\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_1527109/1216600722.py\u001B[0m in \u001B[0;36mgenerate_macro_mask\u001B[0;34m(model_fn, s_f, us_f, n_class, sparsity, x_perc)\u001B[0m\n\u001B[1;32m     22\u001B[0m     \u001B[0;31m# print(us_m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     23\u001B[0m     \u001B[0;31m# print(torch.load(s_f, map_location='cpu')['state_dict'].keys())\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 24\u001B[0;31m     \u001B[0ms_m\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload_state_dict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ms_f\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmap_location\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'cpu'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'state_dict'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     25\u001B[0m     \u001B[0mus_m\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnum_classes\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mn_class\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     26\u001B[0m     \u001B[0mus_m\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload_state_dict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mus_f\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmap_location\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'cpu'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'state_dict'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/nndst/lib/python3.7/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36mload_state_dict\u001B[0;34m(self, state_dict, strict)\u001B[0m\n\u001B[1;32m   1496\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0merror_msgs\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1497\u001B[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001B[0;32m-> 1498\u001B[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001B[0m\u001B[1;32m   1499\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0m_IncompatibleKeys\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmissing_keys\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0munexpected_keys\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1500\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Error(s) in loading state_dict for VGG:\n\tMissing key(s) in state_dict: \"features.2.weight\", \"features.2.bias\", \"features.5.weight\", \"features.5.bias\", \"features.12.weight\", \"features.12.bias\", \"features.19.weight\", \"features.19.bias\", \"features.26.weight\", \"features.26.bias\". \n\tUnexpected key(s) in state_dict: \"features.31.weight\", \"features.31.bias\", \"features.31.running_mean\", \"features.31.running_var\", \"features.31.num_batches_tracked\", \"features.34.weight\", \"features.34.bias\", \"features.35.weight\", \"features.35.bias\", \"features.35.running_mean\", \"features.35.running_var\", \"features.35.num_batches_tracked\", \"features.37.weight\", \"features.37.bias\", \"features.38.weight\", \"features.38.bias\", \"features.38.running_mean\", \"features.38.running_var\", \"features.38.num_batches_tracked\", \"features.40.weight\", \"features.40.bias\", \"features.41.weight\", \"features.41.bias\", \"features.41.running_mean\", \"features.41.running_var\", \"features.41.num_batches_tracked\", \"features.1.weight\", \"features.1.bias\", \"features.1.running_mean\", \"features.1.running_var\", \"features.1.num_batches_tracked\", \"features.3.weight\", \"features.3.bias\", \"features.4.weight\", \"features.4.bias\", \"features.4.running_mean\", \"features.4.running_var\", \"features.4.num_batches_tracked\", \"features.8.weight\", \"features.8.bias\", \"features.8.running_mean\", \"features.8.running_var\", \"features.8.num_batches_tracked\", \"features.11.weight\", \"features.11.bias\", \"features.11.running_mean\", \"features.11.running_var\", \"features.11.num_batches_tracked\", \"features.15.weight\", \"features.15.bias\", \"features.15.running_mean\", \"features.15.running_var\", \"features.15.num_batches_tracked\", \"features.18.weight\", \"features.18.bias\", \"features.18.running_mean\", \"features.18.running_var\", \"features.18.num_batches_tracked\", \"features.20.weight\", \"features.20.bias\", \"features.21.running_mean\", \"features.21.running_var\", \"features.21.num_batches_tracked\", \"features.25.weight\", \"features.25.bias\", \"features.25.running_mean\", \"features.25.running_var\", \"features.25.num_batches_tracked\", \"features.27.weight\", \"features.27.bias\", \"features.28.running_mean\", \"features.28.running_var\", \"features.28.num_batches_tracked\", \"features.30.weight\", \"features.30.bias\". \n\tsize mismatch for features.7.weight: copying a param with shape torch.Size([128, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n\tsize mismatch for features.10.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 128, 3, 3]).\n\tsize mismatch for features.10.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for features.14.weight: copying a param with shape torch.Size([256, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for features.17.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 256, 3, 3]).\n\tsize mismatch for features.17.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for features.21.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n\tsize mismatch for features.21.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for features.24.weight: copying a param with shape torch.Size([512, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n\tsize mismatch for features.28.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3])."
     ]
    }
   ],
   "source": [
    "eb = EarlyBird(SPARSITY)\n",
    "model_fn = eval(f\"torchvision.models.{MODELS[0]}\")\n",
    "output_dirs = '../intersected_macro_masks/cifar10/vgg16'\n",
    "random_init = '../common_models/random_weights/vgg16_10.pth.tar'\n",
    "os.makedirs(output_dirs, exist_ok=True)\n",
    "paired_files = zip(struct_files, unstruct_files)\n",
    "sizes = collections.defaultdict(list)\n",
    "for i, (struct, unstruct) in tqdm.tqdm(enumerate(paired_files), total=len(struct_files)):\n",
    "    s_f = osp.join(structured_dirs, struct)\n",
    "    us_f = osp.join(unstructured_dirs, unstruct)\n",
    "    s_mask, us_mask, macro_mask = generate_macro_mask(model_fn, s_f, us_f, 10, 0.8, 0.55)\n",
    "    model = model_fn(num_classes=10)\n",
    "    model.load_state_dict(torch.load(random_init))\n",
    "    model = apply_marco_mask(model, macro_mask)\n",
    "    torch.save(model.state_dict(), osp.join(output_dirs, f'iou_{i}.pth.tar'))\n",
    "    model.load_state_dict(torch.load(random_init))\n",
    "    model = apply_marco_mask(model, s_mask)\n",
    "    torch.save(model.state_dict(), osp.join(output_dirs, f'struct_{i}.pth.tar'))\n",
    "    model.load_state_dict(torch.load(random_init))\n",
    "    model = apply_marco_mask(model, us_mask)\n",
    "    torch.save(model.state_dict(), osp.join(output_dirs, f'unstruct_{i}.pth.tar'))\n",
    "    sizes['s_mask'].append(s_mask.sum()/s_mask.size(0))\n",
    "    sizes['us_mask'].append(us_mask.sum()/us_mask.size(0))\n",
    "    sizes['macro_mask'].append(macro_mask.sum()/macro_mask.size(0))\n",
    "\n",
    "    \n",
    "#     print(f\"s_mask: {s_mask.sum()/s_mask.size(0)}\")\n",
    "#     print(f\"us_mask: {us_mask.sum()/us_mask.size(0)}\")\n",
    "#     print(f\"marco_mask: {macro_mask.sum()/macro_mask.size(0)}\")\n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d889a70",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "compatibility = np.zeros((len(sizes['s_mask']), 3))\n",
    "for i in range(len(sizes['s_mask'])):\n",
    "    compatibility[i][0] = sizes['s_mask'][i]\n",
    "    compatibility[i][1] = sizes['us_mask'][i]\n",
    "    compatibility[i][2] = sizes['macro_mask'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8946b5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "path = 'vgg16_sparsity_ratio.txt'\n",
    "np.savetxt(path, compatibility, delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}